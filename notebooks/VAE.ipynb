{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PkWD6PSX5dQx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tb-McRvK5dQ1",
    "outputId": "069589b2-3a9c-47b2-dd99-fa137757de49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 14:28:49.124251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-29 14:28:50.108458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6476 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:03:00.0, compute capability: 7.5\n",
      "2022-07-29 14:28:50.109044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6647 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset = tfds.load('mnist', split='train') # MNIST Data load \n",
    "train_data = dataset.map(lambda data: tf.cast(data['image'], tf.float32) / 255.).batch(1024) # data에서 이미지정보만 뽑아서 Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class Vanila_Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(latent_dim * 2)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        mu, logvar = tf.split(self.encoder(x), 2, axis=1) ## self.encoder(x)의 값을 1축 방향으로 반으로 나누어 쪼갠뒤 각각의 값을 mu, logvar로 만듭니다.\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class Vanila_Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(256, activation='relu'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Dense(512, activation='relu'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Dense(784, activation='sigmoid'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Reshape((28,28, 1))\n",
    "        ])\n",
    "        \n",
    "    def call(self, z):\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 하이퍼 파라미터 세팅\n",
    "n_epochs = 50\n",
    "latent_dim = 2\n",
    "learning_rate = 1e-3\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9ofy2-su5dQ6"
   },
   "outputs": [],
   "source": [
    "# 모델 객체 생성 위에서 만든 붕어빵 틀로 붕어빵 만드는 과정!\n",
    "encoder = Vanila_Encoder(latent_dim)\n",
    "decoder = Vanila_Decoder(latent_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링 하는 과정\n",
    "def sample(mu, logvar):\n",
    "    epsilon = tf.random.normal(mu.shape)\n",
    "    sigma = tf.exp(0.5 * logvar) ## var==sigma^2 \n",
    "    return epsilon * sigma + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input을 받아서 Gradient descent 한 번 하는 과정까지!\n",
    "@tf.function # decorator 즉시 실행으로 바꿔줌\n",
    "def train_step(inputs):\n",
    "    with tf.GradientTape() as tape: # 이 부분은 그래디언트를 추적하겠다!\n",
    "        mu, logvar = encoder(inputs) # (batch, latent_dim), (batch, latent_dim) q(z|x)\n",
    "        z = sample(mu, logvar) # 인코더에서 뽑은 평균과 분산으로 샘플링 \n",
    "        x_recon = decoder(z) # 샘플링된 것을 다시 Recon p(x|z)\n",
    "        reconstruction_error = tf.reduce_sum(tf.losses.binary_crossentropy(inputs, x_recon)) # log p(x|z)\n",
    "        kl = 0.5 * tf.reduce_sum(tf.exp(logvar) + tf.square(mu) - 1. - logvar) # KL(p(z)|q(z|x))\n",
    "        loss = (kl + reconstruction_error) / inputs.shape[0] # 각 샘플당 로스로!\n",
    "         \n",
    "    vars_ = encoder.trainable_variables + decoder.trainable_variables # get trainable parameter\n",
    "    grads_ = tape.gradient(loss, vars_) # get grads\n",
    "    optimizer.apply_gradients(zip(grads_, vars_)) # applyling gradient descent\n",
    "\n",
    "    return loss, reconstruction_error, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10 iteration: ELBO 157.20, Recon 151.73, KL 5.46\n",
      " 20 iteration: ELBO 149.57, Recon 143.60, KL 5.98\n",
      " 30 iteration: ELBO 145.82, Recon 139.55, KL 6.26\n",
      " 40 iteration: ELBO 143.42, Recon 136.98, KL 6.44\n",
      " 50 iteration: ELBO 141.53, Recon 135.00, KL 6.53\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):    \n",
    "    total_loss, total_recon, total_kl = 0, 0, 0\n",
    "    for x in train_data:\n",
    "        loss, recon, kl = train_step(x)\n",
    "        # loss 저장\n",
    "        total_loss += loss * x.shape[0]\n",
    "        # error 저장\n",
    "        total_recon += recon\n",
    "        # total KL 저장\n",
    "        total_kl += kl\n",
    "    \n",
    "    if epoch % log_interval == 0:\n",
    "        # epoch 동안 평균 로스\n",
    "        print(\n",
    "            f'{epoch:3d} iteration: ELBO {total_loss / len(dataset):.2f}, ' \\\n",
    "            f'Recon {total_recon / len(dataset):.2f}, ' \\\n",
    "            f'KL {total_kl / len(dataset):.2f}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa6e072fe90>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = tf.zeros((1, latent_dim))\n",
    "logvar = tf.zeros((1, latent_dim))\n",
    "\n",
    "z = sample(mu, logvar)\n",
    "x = decoder(z)\n",
    "plt.imshow(x[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability==0.6.0\r\n",
      "  Downloading tensorflow_probability-0.6.0-py2.py3-none-any.whl (790 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m790.8/790.8 kB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.13.3 in ./anaconda3/envs/pytorch/lib/python3.7/site-packages (from tensorflow-probability==0.6.0) (1.21.6)\r\n",
      "Requirement already satisfied: six>=1.10.0 in ./anaconda3/envs/pytorch/lib/python3.7/site-packages (from tensorflow-probability==0.6.0) (1.16.0)\r\n",
      "Installing collected packages: tensorflow-probability\r\n",
      "Successfully installed tensorflow-probability-0.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-probability==0.6.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_30090/3205720027.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow_probability\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtfp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# -2~2까지 z값에 대하여 뽑기!\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mplot_latent_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdigit_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m28\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m  \u001B[0;31m# pylint: disable=wildcard-import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mversion\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m__version__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[0;31m# pylint: enable=g-import-not-at-top\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/python/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mprint_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbijectors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdistributions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0medward2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmasked_autoregressive\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMaskedAutoregressiveFlow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatrix_inverse_tril\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMatrixInverseTriL\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 46\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatveclu\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMatvecLU\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     47\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal_cdf\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mNormalCDF\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mordered\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mOrdered\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/matveclu.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbijectors\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbijector\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlu_reconstruct\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlu_solve\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/python/math/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcustom_gradient\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcustom_gradient\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdiag_jacobian\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdiag_jacobian\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minterpolation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbatch_interp_regular_1d_grid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow_probability\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minterpolation\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0minterp_regular_1d_grid\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow_probability/python/math/diag_jacobian.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m \u001B[0mtfe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meager\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m __all__ = [\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "# -2~2까지 z값에 대하여 뽑기!\n",
    "def plot_latent_images(n, digit_size=28):\n",
    "    digit_size = 28\n",
    "    scale = 2.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder(z_sample).numpy()\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_latent_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_30090/2229167978.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mplot_latent_images\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'plot_latent_images' is not defined"
     ]
    }
   ],
   "source": [
    "plot_latent_images(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tfds.load('mnist', split='test') # MNIST Data load \n",
    "test_data = test_dataset.map(lambda data: (tf.cast(data['image'], tf.float32) / 255., data['label'])).batch(1024) # data에서 이미지정보만 뽑아서 Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = []\n",
    "y_axis = []\n",
    "label_list = []\n",
    "for image, label in test_data:\n",
    "    mu, logvar = encoder(image)\n",
    "    x_axis.append(mu[:,0] + tf.exp(0.5*logvar)[:,0])\n",
    "    y_axis.append(mu[:,1] + tf.exp(0.5*logvar)[:,1])\n",
    "    label_list.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.concatenate(x_axis, axis=0)\n",
    "y_axis = np.concatenate(y_axis, axis=0)\n",
    "label_list = np.concatenate(label_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = plt.scatter(x_axis, y_axis, c=label_list, label=label_list)\n",
    "plt.legend(handles = scatter_plot.legend_elements()[0], labels=[i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sample = next(iter(test_dataset))['image']\n",
    "image_sample = tf.expand_dims(image_sample, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, logvar = encoder(image_sample/255)\n",
    "z = sample(mu, logvar)\n",
    "print(mu)\n",
    "x = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_sample[0,:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition_Encoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.depth = 10\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(latent_dim * 2)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, label):\n",
    "        x = self.flatten(x)\n",
    "        label = tf.one_hot(label, self.depth)\n",
    "        x = tf.keras.layers.concatenate([x, label])\n",
    "        mu, logvar = tf.split(self.encoder(x), 2, axis=1) ## self.encoder(x)의 값을 1축 방향으로 반으로 나누어 쪼갠뒤 각각의 값을 mu, logvar로 만듭니다.\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition_Decoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.depth = 10\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(256, activation='relu'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Dense(512, activation='relu'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Dense(784, activation='sigmoid'), # (batch, 7*7*32) , input_shape=(latent_dim,)\n",
    "            layers.Reshape((28,28, 1))\n",
    "        ])\n",
    "        \n",
    "    def call(self, z, label):\n",
    "        label = tf.one_hot(label, self.depth)\n",
    "        z = tf.keras.layers.concatenate([z, label])\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_encoder = Condition_Encoder(2)\n",
    "condition_decoder = Condition_Decoder(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load('mnist', split='train') # MNIST Data load \n",
    "train_data = dataset.map(lambda data: (tf.cast(data['image'], tf.float32) / 255., data['label'])).batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # decorator 즉시 실행으로 바꿔줌\n",
    "def train_step_condition(inputs, label):\n",
    "    with tf.GradientTape() as tape: # 이 부분은 그래디언트를 추적하겠다!\n",
    "        mu, logvar = condition_encoder(inputs, label) # (batch, latent_dim), (batch, latent_dim) q(z|x)\n",
    "        z = sample(mu, logvar) # 인코더에서 뽑은 평균과 분산으로 샘플링 \n",
    "        x_recon = condition_decoder(z, label) # 샘플링된 것을 다시 Recon p(x|z)\n",
    "        reconstruction_error = tf.reduce_sum(tf.losses.binary_crossentropy(inputs, x_recon)) # log p(x|z)\n",
    "        kl = 0.5 * tf.reduce_sum(tf.exp(logvar) + tf.square(mu) - 1. - logvar) # KL(p(z)|q(z|x))\n",
    "        loss = (kl + reconstruction_error) / inputs.shape[0] # 각 샘플당 로스로!\n",
    "         \n",
    "    vars_ = condition_encoder.trainable_variables + condition_decoder.trainable_variables # get trainable parameter\n",
    "    grads_ = tape.gradient(loss, vars_) # get grads\n",
    "    optimizer.apply_gradients(zip(grads_, vars_)) # applyling gradient descent\n",
    "\n",
    "    return loss, reconstruction_error, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):    \n",
    "    total_loss, total_recon, total_kl = 0, 0, 0\n",
    "    for x, y in train_data:\n",
    "        loss, recon, kl = train_step_condition(x, y)\n",
    "        # loss 저장\n",
    "        total_loss += loss * x.shape[0]\n",
    "        # error 저장\n",
    "        total_recon += recon\n",
    "        # total KL 저장\n",
    "        total_kl += kl\n",
    "    \n",
    "    if epoch % log_interval == 0:\n",
    "        # epoch 동안 평균 로스\n",
    "        print(\n",
    "            f'{epoch:3d} iteration: ELBO {total_loss / len(dataset):.2f}, ' \\\n",
    "            f'Recon {total_recon / len(dataset):.2f}, ' \\\n",
    "            f'KL {total_kl / len(dataset):.2f}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = tf.zeros((1, latent_dim))\n",
    "logvar = tf.zeros((1, latent_dim))\n",
    "z = sample(mu, logvar)\n",
    "label = tf.convert_to_tensor([3])\n",
    "x = condition_decoder(z, label)\n",
    "plt.imshow(x[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}